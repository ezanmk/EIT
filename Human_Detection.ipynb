{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_PgNNHevipW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ff94beb-5542-4df6-e754-0e4959fe7d2f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.metrics import Recall,Precision\n",
        "from tensorflow_addons.metrics import F1Score\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten\n",
        "import os \n",
        "from os import listdir\n",
        "from PIL import Image as PImage\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "np.random.seed(9001)\n",
        "#WHAT!? 9000!?!?"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dziI2qfBxBP1",
        "outputId": "1c965d8b-fa0e-4a6c-cdec-80a01d23da6f"
      },
      "source": [
        "pip install tensorflow_addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.13.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "w9Q_s863wBfJ",
        "outputId": "531c62de-857f-4e51-e8bd-04dc7ad16e2d"
      },
      "source": [
        "'''#K Fold Cross Validation\n",
        "shuffle_ind=np.random.permutation(len(df))\n",
        "i=1\n",
        "while i<=k:\n",
        "  k_end=int(len(df)*(i/k))\n",
        "  k_start=int(len(df)*(i-1/k))\n",
        "  k_fold=shuffle_ind[k_start:k_end]\n",
        "  trainL=shuffle_ind[0:k_start]\n",
        "  trainR=shuffle_ind[k_end:]\n",
        "  train=np.concatenate(trainL,trainR)\n",
        "  i+=1'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#K Fold Cross Validation\\nshuffle_ind=np.random.permutation(len(df))\\ni=1\\nwhile i<=k:\\n  k_end=int(len(df)*(i/k))\\n  k_start=int(len(df)*(i-1/k))\\n  k_fold=shuffle_ind[k_start:k_end]\\n  trainL=shuffle_ind[0:k_start]\\n  trainR=shuffle_ind[k_end:]\\n  train=np.concatenate(trainL,trainR)\\n  i+=1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "RdhjiiIIVxgL",
        "outputId": "d8dcc962-32b9-4a72-d7c9-c39e74b5b6b2"
      },
      "source": [
        "'''base_dir='gdrive/My Drive/Colab Notebooks/CNN/INRIAPerson/Train\n",
        "#tensor dataframes allow for a lazy load to the images\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  base_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=9001,\n",
        "  shuffle=True,\n",
        "  #image_size=(img_height, img_width),\n",
        "  batch_size=1\n",
        ")'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'base_dir=\\'gdrive/My Drive/Colab Notebooks/CNN/INRIAPerson/Train\\n#tensor dataframes allow for a lazy load to the images\\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\\n  base_dir,\\n  validation_split=0.2,\\n  subset=\"training\",\\n  seed=9001,\\n  shuffle=True,\\n  #image_size=(img_height, img_width),\\n  batch_size=1\\n)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "m6zBKb1lxU4L",
        "outputId": "08527f5d-9f79-40e4-9e1e-fa95b672e010"
      },
      "source": [
        "'''val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  base_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=9001,\n",
        "  shuffle=True,\n",
        "  #image_size=(img_height, img_width),\n",
        "  batch_size=1\n",
        ")'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'val_ds = tf.keras.preprocessing.image_dataset_from_directory(\\n  base_dir,\\n  validation_split=0.2,\\n  subset=\"validation\",\\n  seed=9001,\\n  shuffle=True,\\n  #image_size=(img_height, img_width),\\n  batch_size=1\\n)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OmG969yEyQEU",
        "outputId": "b92e8615-a13a-44d2-b6a5-d571a549068a"
      },
      "source": [
        "'''for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'for image_batch, labels_batch in train_ds:\\n  print(image_batch.shape)\\n  print(labels_batch.shape)\\n  break'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMpZ9-x1vRJr"
      },
      "source": [
        "Load All positive images for augmentation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi0MBDp4uzKf"
      },
      "source": [
        "# def loadImages(path):\n",
        "#     # return array of images\n",
        "\n",
        "#     imagesList = listdir(path)\n",
        "#     loadedImages = []\n",
        "#     for image in imagesList:\n",
        "#         img = PImage.open(path + image)\n",
        "#         loadedImages.append(img)\n",
        "\n",
        "#     return loadedImages\n",
        "# # your images in an array\n",
        "# imgs = loadImages('gdrive/My Drive/Colab Notebooks/Human_Detection/INRIAPerson/Train/pos/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "K6zB4JhUKXvq",
        "outputId": "8f2832ad-2a4a-4ae7-a3bc-75194944f8ce"
      },
      "source": [
        "#Just Makes it lighter\n",
        "'''def noise (image):\n",
        "  noise = np.random.randint(0,150)\n",
        "  newimgdata = []\n",
        "  #hard code number of pixel values\n",
        "  for color in image.getdata():\n",
        "    newpix=[]\n",
        "    for i in range(len(color)):\n",
        "      if color[i]!=255:\n",
        "        p =color[i] + noise\n",
        "      newpix.append( p )\n",
        "    newpix=tuple(newpix)\n",
        "    newimgdata.append(newpix)\n",
        "  newimg = PImage.new(img.mode,img.size)\n",
        "  newimg.putdata(newimgdata)\n",
        "  return newimg\n",
        "noise(img)'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'def noise (image):\\n  noise = np.random.randint(0,150)\\n  newimgdata = []\\n  #hard code number of pixel values\\n  for color in image.getdata():\\n    newpix=[]\\n    for i in range(len(color)):\\n      if color[i]!=255:\\n        p =color[i] + noise\\n      newpix.append( p )\\n    newpix=tuple(newpix)\\n    newimgdata.append(newpix)\\n  newimg = PImage.new(img.mode,img.size)\\n  newimg.putdata(newimgdata)\\n  return newimg\\nnoise(img)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc7vGTIpvaEu"
      },
      "source": [
        "Functon for adding noise to random pixel components throughout the image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOvpGdv3VMPQ"
      },
      "source": [
        "# def noise (image):\n",
        "#   noise = np.random.randint(0,150)\n",
        "#   newimgdata = []\n",
        "#   for color in image.getdata():\n",
        "#     rand_ind = np.random.randint(0,len(color)-1)\n",
        "#     newpix=[]\n",
        "#     for i in range(len(color)):\n",
        "#       if i==rand_ind:\n",
        "#         if color[i]!=255:\n",
        "#           p =color[i] + noise\n",
        "#           newpix.append( p )\n",
        "#         else:\n",
        "#           newpix.append(color[i])\n",
        "#       else:\n",
        "#         newpix.append(color[i])\n",
        "#     newpix=tuple(newpix)\n",
        "#     newimgdata.append(newpix)\n",
        "#   newimg = PImage.new(img.mode,img.size)\n",
        "#   newimg.putdata(newimgdata,scale=1.0, offset=0.0)\n",
        "#   return newimg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl8HMCIpvpUg"
      },
      "source": [
        "Augment positive images (horizontal flip, vertical flip, noise, and 90 degree rotation):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pJKOH6EwQfE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "3ddd9966-3442-464d-a576-a8ffd34e6002"
      },
      "source": [
        "'''aug_dir='/content/gdrive/MyDrive/Colab Notebooks/Human_Detection/INRIAPerson/TrainA/pos/'\n",
        "i = 0\n",
        "for img in imgs:\n",
        "  hoz_flip = img.transpose(PImage.FLIP_LEFT_RIGHT)\n",
        "  hoz_flip.save(aug_dir+f\"{i}\"+\"hoz.png\")\n",
        "  ver_flip = img.transpose(PImage.FLIP_TOP_BOTTOM)\n",
        "  ver_flip.save(aug_dir+f\"{i}\"+\"vert.png\")\n",
        "  noisey=noise(img)\n",
        "  noisey.save(aug_dir+f\"{i}\"+\"noisey.png\")\n",
        "  rot=img.rotate(90)\n",
        "  rot.save(aug_dir+f\"{i}\"+\"rot.png\")\n",
        "  i+=1'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'aug_dir=\\'/content/gdrive/MyDrive/Colab Notebooks/Human_Detection/INRIAPerson/TrainA/pos/\\'\\ni = 0\\nfor img in imgs:\\n  hoz_flip = img.transpose(PImage.FLIP_LEFT_RIGHT)\\n  hoz_flip.save(aug_dir+f\"{i}\"+\"hoz.png\")\\n  ver_flip = img.transpose(PImage.FLIP_TOP_BOTTOM)\\n  ver_flip.save(aug_dir+f\"{i}\"+\"vert.png\")\\n  noisey=noise(img)\\n  noisey.save(aug_dir+f\"{i}\"+\"noisey.png\")\\n  rot=img.rotate(90)\\n  rot.save(aug_dir+f\"{i}\"+\"rot.png\")\\n  i+=1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANyescjsE9H2"
      },
      "source": [
        "Load negative images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ56v8jSsteQ"
      },
      "source": [
        "# # your images in an array\n",
        "# imgs = loadImages('gdrive/My Drive/Colab Notebooks/Human_Detection/INRIAPerson/Train/neg/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqJhNbjGmPd1"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOaEEpdfx-mo"
      },
      "source": [
        "Augment negative:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07Vk6hhMvMCY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "685379c0-38a5-4e45-9f4b-ae5f7c83b955"
      },
      "source": [
        "'''aug_dir='/content/gdrive/MyDrive/Colab Notebooks/Human_Detection/INRIAPerson/TrainA/neg/'\n",
        "i = 0\n",
        "for img in imgs:\n",
        "  hoz_flip = img.transpose(PImage.FLIP_LEFT_RIGHT)\n",
        "  hoz_flip.save(aug_dir+f\"{i}\"+\"hoz.png\")\n",
        "  ver_flip = img.transpose(PImage.FLIP_TOP_BOTTOM)\n",
        "  ver_flip.save(aug_dir+f\"{i}\"+\"vert.png\")\n",
        "  noisey=noise(img)\n",
        "  noisey.save(aug_dir+f\"{i}\"+\"noisey.png\")\n",
        "  rot=img.rotate(90)\n",
        "  rot.save(aug_dir+f\"{i}\"+\"rot.png\")\n",
        "  i+=1'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'aug_dir=\\'/content/gdrive/MyDrive/Colab Notebooks/Human_Detection/INRIAPerson/TrainA/neg/\\'\\ni = 0\\nfor img in imgs:\\n  hoz_flip = img.transpose(PImage.FLIP_LEFT_RIGHT)\\n  hoz_flip.save(aug_dir+f\"{i}\"+\"hoz.png\")\\n  ver_flip = img.transpose(PImage.FLIP_TOP_BOTTOM)\\n  ver_flip.save(aug_dir+f\"{i}\"+\"vert.png\")\\n  noisey=noise(img)\\n  noisey.save(aug_dir+f\"{i}\"+\"noisey.png\")\\n  rot=img.rotate(90)\\n  rot.save(aug_dir+f\"{i}\"+\"rot.png\")\\n  i+=1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc152hTJgEJz"
      },
      "source": [
        "# def combine_generator(gen1, gen2):\n",
        "#     while True:\n",
        "#         yield(next(gen1), next(gen2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLfCrDAeyD9M",
        "outputId": "76f07cb5-50ff-4968-fe89-9ad413869ec8"
      },
      "source": [
        "base_dir='gdrive/My Drive/Colab Notebooks/Human_Detection/INRIAPerson/Train'\n",
        "#Rescaling\n",
        "train_datagen=ImageDataGenerator(rescale=1./255, validation_split=.2, dtype=tf.uint8)\n",
        "val_datagen=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "val_generator=train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1467 images belonging to 2 classes.\n",
            "Found 365 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0vLFwTSuR8e"
      },
      "source": [
        "# base_dir='gdrive/My Drive/Colab Notebooks/Human_Detection/INRIAPerson/TrainA'\n",
        "# #Rescaling\n",
        "# train_datagen=ImageDataGenerator(rescale=1./255, dtype=tf.uint8)\n",
        "# train_generator=train_datagen.flow_from_directory(\n",
        "#     base_dir,\n",
        "#     target_size=(224,224),\n",
        "#     batch_size=32,\n",
        "#     shuffle=True,\n",
        "#     class_mode='binary',\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oACQVeOyHGVP"
      },
      "source": [
        "# base_dir='gdrive/My Drive/Colab Notebooks/Human_Detection/INRIAPerson/Augmented_Train/Positive'\n",
        "# #Rescaling\n",
        "# augPos_datagen=ImageDataGenerator(rescale=1./255, dtype=tf.uint8)\n",
        "# train_generator=train_datagen.flow_from_directory(\n",
        "#     base_dir,\n",
        "#     target_size=(224,224),\n",
        "#     batch_size=32,\n",
        "#     shuffle=True,\n",
        "#     class_mode='binary',\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0fFDWyJPRZK"
      },
      "source": [
        "# base_dir='gdrive/My Drive/Colab Notebooks/Human_Detection/INRIAPerson/Augmented_Train/Negative'\n",
        "# #Rescaling\n",
        "# augNeg_datagen=ImageDataGenerator(rescale=1./255, validation_split=.5, dtype=tf.uint8)\n",
        "# train_generator=train_datagen.flow_from_directory(\n",
        "#     base_dir,\n",
        "#     target_size=(224,224),\n",
        "#     batch_size=32,\n",
        "#     shuffle=True,\n",
        "#     class_mode='binary',\n",
        "#     subset='training'\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTHqEYw3ccz0",
        "outputId": "d0e88762-fcc7-4cce-a166-715310b9f3f2"
      },
      "source": [
        "base_dir='gdrive/My Drive/Colab Notebooks/Human_Detection/INRIAPerson/Test'\n",
        "#Rescaling\n",
        "test_datagen=ImageDataGenerator(rescale=1./255, dtype=tf.uint8)\n",
        "test_generator=train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(224,224),\n",
        "    batch_size=741,\n",
        "    shuffle=True,\n",
        "    class_mode='binary',\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 741 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYSyBaCejIjd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7038d57c-6a0b-4ccf-ead3-6d8a2132f64b"
      },
      "source": [
        "mobilenet_v2 = tf.keras.applications.mobilenet_v2.MobileNetV2(include_top=False,\n",
        "                                                              input_shape=(224, 224, 3),\n",
        "                                                              weights=\"imagenet\",\n",
        "                                                              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi8-rziXXsIo"
      },
      "source": [
        "mobilenet_v2.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtg0HInnB2pk",
        "outputId": "d939b2d7-dec9-47f6-c938-3da47a2fc2d7"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    Input((224, 224, 3)),\n",
        "    mobilenet_v2,\n",
        "    Flatten(),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_DZRC6pGOyC"
      },
      "source": [
        "model.compile(optimizer='Adam',loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy',F1Score(num_classes=1),Precision(),Recall()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTG7WlcDJTb1",
        "outputId": "b88c8f7d-6b60-42e6-cfa2-6795b4ab34c7"
      },
      "source": [
        "history=model.fit(train_generator, validation_data=val_generator,epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1693 - accuracy: 0.9850 - f1_score: 0.8319 - precision: 0.9757 - recall: 0.9797"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r46/46 [==============================] - 272s 6s/step - loss: 0.1693 - accuracy: 0.9850 - f1_score: 0.8319 - precision: 0.9757 - recall: 0.9797 - val_loss: 0.1319 - val_accuracy: 0.9973 - val_f1_score: 0.9878 - val_precision: 1.0000 - val_recall: 0.9918\n",
            "Epoch 2/5\n",
            "46/46 [==============================] - 51s 1s/step - loss: 0.0974 - accuracy: 0.9864 - f1_score: 0.9101 - precision: 0.9777 - recall: 0.9817 - val_loss: 0.2488 - val_accuracy: 0.9945 - val_f1_score: 0.9959 - val_precision: 1.0000 - val_recall: 0.9836\n",
            "Epoch 3/5\n",
            "46/46 [==============================] - 51s 1s/step - loss: 0.1172 - accuracy: 0.9939 - f1_score: 0.9553 - precision: 0.9899 - recall: 0.9919 - val_loss: 0.1896 - val_accuracy: 0.9945 - val_f1_score: 0.9959 - val_precision: 1.0000 - val_recall: 0.9836\n",
            "Epoch 4/5\n",
            "46/46 [==============================] - 50s 1s/step - loss: 0.1798 - accuracy: 0.9864 - f1_score: 0.9514 - precision: 0.9797 - recall: 0.9797 - val_loss: 0.1770 - val_accuracy: 0.9973 - val_f1_score: 0.9918 - val_precision: 1.0000 - val_recall: 0.9918\n",
            "Epoch 5/5\n",
            "46/46 [==============================] - 50s 1s/step - loss: 0.0552 - accuracy: 0.9952 - f1_score: 0.9870 - precision: 0.9939 - recall: 0.9919 - val_loss: 0.2338 - val_accuracy: 0.9973 - val_f1_score: 0.9918 - val_precision: 1.0000 - val_recall: 0.9918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwoOgDfcowMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81cbc736-aa14-413c-e7bc-87bcdc54a728"
      },
      "source": [
        "model.evaluate(test_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 31s 31s/step - loss: 0.9725 - accuracy: 0.9663 - f1_score: 0.9637 - precision: 0.9925 - recall: 0.9201\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9725031852722168,\n",
              " 0.9662618041038513,\n",
              " array([0.9637306], dtype=float32),\n",
              " 0.9925093650817871,\n",
              " 0.9201388955116272]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtvzPoGOkxw_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "185fcd2c-297a-410b-a805-f905ce409579"
      },
      "source": [
        "xs = range(len(history.history[\"accuracy\"]))\n",
        "plt.plot(xs, history.history[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7ffc649e50>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9dnw/89FViCBCAkBkkACWTAgmxHZN9msFW/R1qVaF7j7WLXaCnq3d1+vPr/b59XHXwvu1dufBR612qqPWhssNuxCZBFEwp6QDcgCWYCEJGT//v6YgaZjMBOYmTPL9X698mJyzvecc80hZ645Z841lxhjUEopFXh6WB2AUkopa2gCUEqpAKUJQCmlApQmAKWUClCaAJRSKkAFWx1Ad0RHR5vExESrw1BKKZ/y9ddfVxljYhyn+1QCSExMZM+ePVaHoZRSPkVEjnc2XS8BKaVUgNIEoJRSAUoTgFJKBShNAEopFaA0ASilVIDSBKCUUgFKE4BSSgUoTQBKKeXFTtU08tzaI1Seb3L5ujUBKKWUF3t7RzF/3FZIY0uby9etCUAppbxUfVMr7+08zvyRA0no18vl69cEoJRSXurjvSXUNrayZFqSW9avCUAppbxQe7thdXYRYxOiGD/kGrdsQxOAUkp5oY1HKyiubmDJtCRExC3b0ASglFJeaOW2QuKierJg5EC3bUMTgFJKeZmDpTXsKjrDg5MTCQ5y38u0JgCllPIyq7KL6B0axF0TEty6HU0ASinlRU7VNLImp4wf3pBAn/AQt25LE4BSSnmRt3cU024MD012z62fHWkCUEopL9HQ3Mqfd51g/siBDOnv+sIvR5oAlFLKS3z8dQk1F1rcVvjlSBOAUkp5gfZ2w6rsIsa4sfDLkSYApZTyApcKv6a6r/DLkSYApZTyAquybYVfN49yX+GXI00ASillsYOlNewsPMMDk4e6tfDLkSYApZSy2KXCrxuGeHS7mgCUUspCHQu/+vZ0b+GXI00ASilloXd2eK7wy5EmAKWUskhDcyvv7TrBvHTPFH450gSglFIW+XhvqUcLvxw5lQBEZIGI5IpIvoj8spP5Q0Vko4jsF5EtIhLfYd7vROSg/eeuTpZ9RUTqru5pKKWUb7nY8WtMQhTXD/VM4ZejLhOAiAQBrwE3A+nAPSKS7jBsBfCOMWY08CzwnH3ZW4DxwFjgRmCZiPTpsO4MwJpnrpRSFtp0tIKiqnoWe7Dwy5EzZwATgHxjTKExphl4H7jNYUw6sMn+eHOH+enAVmNMqzGmHtgPLIBLiWU58MzVPQWllPI9K7MLGdw33KOFX46cSQBxwMkOv5fYp3WUAyyyP74diBSR/vbpC0Skl4hEA7OAix0OHgcyjTHl37VxEfmJiOwRkT2VlZVOhKuUUt7tYuHXg1MSCfFg4ZcjV215GTBDRL4BZgClQJsxZh2wFtgO/AXYAbSJyGDgB8CrXa3YGPOmMSbDGJMRExPjonCVcp22dkNtY4vVYSgfsjq7iF4WFH45ciYBlPLPd+0A8fZplxhjyowxi4wx44Bf26eds//7W2PMWGPMXECAPGAckAzki0gx0EtE8q/2yShlhefWHmH67zdzpr7Z6lCUDzhd20hmThk/zPB84ZcjZxLAbiBFRJJEJBS4G8jsOEBEokXk4rp+Bay2Tw+yXwpCREYDo4F1xpi/G2MGGmMSjTGJQIMxJtk1T0kpzzl5poG3dxRzrqGF/96i72FU197ZUUybMTw8xZpbPzvqMgEYY1qxXa/PAo4AHxpjDonIsyKy0D5sJpArInlALPBb+/QQYJuIHAbeBO6zr08pv/DyxmOICDPTYnh7x3HKay5YHZLyYhcLv+ZbVPjlKNiZQcaYtdiu5Xec9psOjz8CPupkuUZsdwJ1tf4IZ+JQypvkV5znk70lPDwliQcmJzL7+S28uimf/337dVaHprzUx3tLOdfQwmKLCr8caSWwUlfo+XV59AwJ4qczh5PQrxf3TBjCh7tPUlxVb3VoygtdKvyK70uGRYVfjjQBKHUF9pec4/ODp1gybRj9I8IAeHx2MsFBwosb8iyOTnmjzbn2wq9pwywr/HKkCUCpK7A8K5dreoX8y3e4DIgM56EpSWTmlHGkvNbC6JQ3WrmtiEEWF3450gSgVDftKKhm27EqHp2ZTGT4v97G98j04USEBfP8ulyLolPe6FBZDTsKq3lwsrWFX468JxKlfIAxhhXrcontE8b9k4Z+a37fXiE8MmM4G45U8PXxsxZEqLzRKnvh190TrC38cqQJQKlu2HTU9sL+xE0phIcEdTrmwcmJREeEsjzrKMYYD0eovM3pWnvHLy8o/HKkCUApJ7W3G5Zn5TK0fy9+mJFw2XG9w4J5fFYyOwvPkJ1f5cEIlTd6Z0cxre2Gh6YkWh3Kt2gCUMpJnx0o5+ip8zw1N7XL67j33DiEuKieLM/K1bOAAHahuc3e8SuWof17Wx3Ot2gCUMoJLW3tvLAulxEDI7l19OAux4cFB/HknBT2l9SQdeiUByJU3ujjvSWca2hhybRhVofSKU0ASjnho69LKK5uYNm8NHr0cO4e7kXj4hge05sV6/Joa9ezgEBzsfBrtBcVfjnSBKBUFxpb2nh5wzHGD4nipmsHOL1ccFAPls5LI7+ijk+/Ke16AeVXNudWUGhxx6+uaAJQqgvv7jzOqdpGnp4/otsH8s2jBnJdXF9e3JBHc2u7myJU3mhVtq3w63vXDbI6lMvSBKDUdzjf2MJrm/OZlhLNpOH9u728iLBsfholZy/w/u4TbohQeaNDZTVsL/C+wi9H3huZUl5gVXYRZxtaWDYv7YrXMT0lmglJ/XhlYz4Nzfpt6IHAWwu/HGkCUOoyztQ3s3JbEQtGDmRMQtQVr0dEeGZ+GlV1Tby1vdh1ASqvVOHFhV+ONAEodRlvfFFAfXMrS+elXvW6MhL7MXvEAN7YUkDNBe0f7M/e2XHcawu/HGkCUKoTp2oaeXt7MbePiyMlNtIl61w6L5Xaxlbe3FrgkvUp73OhuY13dx1n7rXeWfjlSBOAUp14ZdMx2o3hF3Ou/t3/RSMH9+XWMYNZnV1M5fkml61XeQ9vL/xypAlAKQfFVfV8uPsk90wYQkI/1/Zt/cWcFJrb2nltszaQ9zft7YbVX9oKv25I9M7CL0eaAJRy8OKGPIKDhMdnJ7t83cNiIvjB9fH8edcJSs42uHz9yjpb8ioorPTuwi9HmgCU6uBIeS2ZOWU8NCWJAZHhbtnGEzelgMDLG465Zf3KGhc7fnlz4ZcjTQBKdfD8ulwiwoJ5ZPpwt21jcFRP7p84lI/3lpBfUee27SjPOVxWy/aCah7w8sIvR74TqVJu9vXxs2w4UsEjM4bTt5d7799+dOZweoYE8cJ6bR3pDy4Wft1zg3cXfjnSBKAUtlaPy7OOEh0RyoOTE92+vf4RYSyeNoy1B05xoKTG7dtT7lNR20hmTik/uD7e7W8cXE0TgFJAdn4VOwvP8PisZHqHBXtkm0umJRHVK4Tl2kDep/2z8CvJ6lC6TROACni2d/+5xEX15J4bPXcK3yc8hEdnDmdrXiU7C6s9tl3lOraOX7bCr8Ro7y/8cqQJQAW8rEOn2F9Sw5NzUggL7rzRu7v8eFIisX3CWKGtI33SJ9+UcLahhcVTfe/dP2gCUAGurd2wYl0ew2N6s2hcnMe3Hx4SxM9mp7Dn+Fk251Z4fPvqyrW3G1ZlF3FdXF8mJPWzOpwroglABbRPvyklv6KOpfPSCLbo9r27bkhgSL9eLM/Ko11bR/qML/IqKaysZ8k03yn8cuTUX7yILBCRXBHJF5FfdjJ/qIhsFJH9IrJFROI7zPudiBy0/9zVYfp79nUeFJHVIuJbH58rn9fc2s6LG/IYFdeHBSMHWhZHSFAPnpqbypHyWv5+oNyyOFT3rMwuZGAf3yr8ctRlAhCRIOA14GYgHbhHRNIdhq0A3jHGjAaeBZ6zL3sLMB4YC9wILBORPvZl3gNGANcBPYElV/1slOqG93efoOTsBZ6eP8LpRu/usnDMYEYMjOSF9Xm0tGnrSG93uKyWL/N9r/DLkTORTwDyjTGFxphm4H3gNocx6cAm++PNHeanA1uNMa3GmHpgP7AAwBiz1tgBXwHxKOUhDc2tvLIxnwlJ/ZieEm11OPToISydl0ZRVT0ff11idTiqC6uyi+gZEsS9Xt7xqyvOJIA44GSH30vs0zrKARbZH98ORIpIf/v0BSLSS0SigVlAQscF7Zd+7gf+0f3wlboyb20vpqquiWfmp3nN9ds51w5g3JAoXt54jMaWNqvDUZdxsfDrhxm+V/jlyFXnLsuAGSLyDTADKAXajDHrgLXAduAvwA7A8S/7dWxnCds6W7GI/ERE9ojInsrKSheFqwJZzYUW3thSwOwRA8hI9J67N0SEp+enUV7TyLs7j1sdjrqMP+303cIvR84kgFL+9V17vH3aJcaYMmPMImPMOODX9mnn7P/+1hgz1hgzFxAg7+JyIvI/gRjgqctt3BjzpjEmwxiTERMT4+TTUury3txaQG2ja1o9utrk4dFMTY7m9S0F1DVpA3lv09jSxrs7jzPHRwu/HDmTAHYDKSKSJCKhwN1AZscBIhItIhfX9StgtX16kP1SECIyGhgNrLP/vgSYD9xjjNFPvZRHVJ5vYnV2MbeOGczIwX2tDqdTy+ancaa+mVXbiqwORTn4ZG8pZxtaWOKjhV+OukwAxphW4HEgCzgCfGiMOSQiz4rIQvuwmUCuiOQBscBv7dNDgG0ichh4E7jPvj6AN+xjd4jIPhH5jauelFKX89rmfJrb2nlqrve9+79obEIU80fG8sdthZytb7Y6HGVnK/wq9OnCL0dOfeuVMWYttmv5Haf9psPjj4CPOlmuEdudQJ2t0zPfuKWUXcnZBv686wQ/zIgnyctP35fOS2Pd4a288UUBv/retVaHo7AVfhVU1vPSXWO95saBq+W7N7Aq1U0vbzgGAj+bnWJ1KF1KjY3k9nFxvLW9mFM1jVaHo7Dd+unrhV+ONAGogJBfUcfHe0u4f+JQBkf1tDocp/xiTirtxvDqJm0dabUj5bVk51fxwOREQoP952XTf56JUt/hhfW59AwJ4tGZ7mv16GoJ/Xpx9w1D+GD3SY5X11sdTkDzl8IvR5oAlN87UFLD2gOnWDxtGP0jwqwOp1t+NjuZ4CDhxfV5XQ9WblFxvpHMfWX8wA8KvxxpAlB+b/m6XKJ6hbBkmu/dujegTzgPTk7ibzllHD1Va3U4AendHcdpaW/3i8IvR5oAlF/bWVjN1rxKHp05nD7hvvnu7ZEZw4gIC2ZFlp4FeFpjSxt/shd+efudY1dCE4DyW8YYVmTlEtsnjB9PSrQ6nCsW1SuU/zF9GBuOnGbvibNWhxNQLhZ++WrHr65oAlB+a3NuBXuOn+WJm1IID/Fsq0dXe2hKEtERoazI0gbyntLeblj9ZRGj4vpwo58UfjnSBKD8Unu7YXlWHkP69eKHGQldL+DleocF89isZLYXVJN9rMrqcALCF8cqya+oY8nUYX5T+OVIE4DyS38/UM6R8lqempvq0w07Orr3xiEM7hvO8qyj2kDeA1ZtKyK2T5hfFX458o8jQ6kOWtraeWF9HiMGRrJwzGCrw3GZsOAgfj4nlZySGtYdPm11OH7NXwu/HPnvM1MB6+OvSyiqqmfpvDTLWz262qLxcQyL6c2KrFzatIG826z208IvR5oAlF9pbGnj5Y3HGDckijnXDrA6HJcLDurB0rlpHKuo42/7SrteQHVbxflG/ravjDuvjyeqV6jV4biVJgDlV97deZzymkae9qJWj65286iBjBzchxc35NHcqq00XO2fhV+JVofidpoAlN+oa2rl9S0FTE2OZvJw6xu9u0uPHrbWkSfPXOCD3SesDsevNLa08e6uE9w0IpZhMRFWh+N2mgCU31i1rYgz9c08PT/N6lDcbkZqDBMS+/HKpnwuNGsDeVf56zelnKlv9smvDbkSmgCUXzhb38wftxUyf2QsYxKirA7H7USEpxekUXm+ibe2F1sdjl+wdfwqYuRg/y38cqQJQPmFN74ooL65laXz/P/d/0U3JPZjVloMb3xRQM2FFqvD8XmXCr+mJfnt50eONAEon3eqppG3thdz+7g4UmMjrQ7Ho5bOS6PmQgsrtxVaHYrPW51tK/y65Tr/qR3piiYA5fNe3XSMdmP4xRzvbfTuLqPi+vL90YNYlV1E5fkmq8PxWUdP1bLtWBU/nuTfhV+OAueZKr90vLqeD3af5J4JQ0jo18vqcCzx1NxUmlrbeX1LvtWh+KxV22yFXz+60b8LvxxpAlA+7cX1eQQHCY/PSrY6FMsMi4ngzvHxvLfzBCVnG6wOx+dUnm8KmMIvR5oAlM86eqqWv+WU8eDkJAb0Cbc6HEs9OScFgFc2agP57vrTzsAp/HKkCUD5rBVZeUSEBfPIjGFWh2K5wVE9uW/iUD76uoSCyjqrw/EZjS1tvLvzODeNGBAQhV+ONAEon7T3xFk2HDnN/5g+LOBO2y/nsVnD6RkSxAvrtHWksz61F34tnhqYbyI0ASiftCIrl+iIUL9s1H2l+keEsXhqEn8/UM7B0hqrw/F6xhhW2gu/Jg4LjMIvR5oAlM/JPlbF9oJqHpuVTO+wYKvD8SpLpg8jqlcIK9Zp68iufJFnK/xaPDVwCr8caQJQPsUYw/Kso8RF9eTeALtlzxl9wkP46YzhbMmt5KuiM1aH49VWZRcxIDKM748OnMIvR5oAlE/JOnSanJIanpyTQliwbzd6d5cfT0pkQGSYto78DrmnzrPtmP93/OpK4D5z5XPa2g3Pr8tlWExvFo2Lszocr9UzNIif3ZTC7uKzbMmrtDocr7QquzAgC78cOZUARGSBiOSKSL6I/LKT+UNFZKOI7BeRLSIS32He70TkoP3nrg7Tk0Rkl32dH4iI3sqhvtPf9pVyrKKOpXPTCPaTRu/ucldGAkP69WL5P3Jp19aR/6LyfBOfflPGHdfHBfwdZF0eRSISBLwG3AykA/eISLrDsBXAO8aY0cCzwHP2ZW8BxgNjgRuBZSLSx77M74AXjTHJwFlg8dU/HeWvmlvbeXFDHqPi+nDzqIFWh+P1QoN78Iu5KRwur2XtwXKrw/Eq7+48TnNbOw/rHWROnQFMAPKNMYXGmGbgfeA2hzHpwCb7480d5qcDW40xrcaYemA/sEBsH7nPBj6yj3sb+LcrfxrK332w+wQnz1xgmR82eneXhWPiSIuN5IV1ebS2aetI+Gfh15xrA7Pwy5EzCSAOONnh9xL7tI5ygEX2x7cDkSLS3z59gYj0EpFoYBaQAPQHzhljWr9jnQCIyE9EZI+I7Kms1OuZgehCcxuvbMpnQmI/ZqTGWB2OzwjqISydl0phVT0f7y2xOhyv8Ok3pVTXN/PwVH33D677EHgZMENEvgFmAKVAmzFmHbAW2A78BdgBdKt/nTHmTWNMhjEmIyZGD/5A9Nb2YirPN/H0Av9t9O4uc9NjGZsQxcsbjtHYEtitI42xdfxKH9SHScP6Wx2OV3AmAZRie9d+Ubx92iXGmDJjzCJjzDjg1/Zp5+z//tYYM9YYMxcQIA+oBqJEJPhy61QKoOZCC298UcCstBhuSAzMas2rISI8Mz+NsppG3tsV2A3ktx6r4liAdfzqijMJYDeQYr9rJxS4G8jsOEBEokXk4rp+Bay2Tw+yXwpCREYDo4F1xnZz8mbgTvsyDwB/u9ono/zPH7cWUnOhhWUB0OjdXSYnRzMluT+vb86nrqm16wX81MpthQFf+OWoywRgv07/OJAFHAE+NMYcEpFnRWShfdhMIFdE8oBY4Lf26SHANhE5DLwJ3Nfhuv9/AE+JSD62zwRWueg5KT9Reb6J1V8W8f3Rgxg5uK/V4fi0ZfPSqK5v5v9kF1kdiiW08KtzTn2RijFmLbZr+R2n/abD44/45x09Hcc0YrsTqLN1FmK7w0ipTr2+JZ+m1naemht4rR5dbdyQa5iXHsubWwu5b+JQrukdWPe/r84uIjykB/dOCOzCL0eaCpVXKjnbwHs7T/CD6+P1dj0XWTovjbrmVt7YWmB1KB5Veb6Jv+4r5c7r4wMu8XVFE4DySq9sPAYCT9yUYnUofiNtYCS3j43jrS+LOV3baHU4HvPuzuM0t7brV4d3QhOA8joFlXV89HUJ908cyuConlaH41d+PieVtnbDq5sCo3Vkx45fw/VM8ls0ASiv88K6PHqGBPHozOFWh+J3hvTvxd0TEnj/q5OcqPb/BvJ/22cr/Fo8Td/9d0YTgPIqB0tr+PuBchZPTaJ/RJjV4filJ2anEBwkvLjBv1tHGmNYua2Ia7Xw67I0ASivsjwrl6heISyZHpg9Wj1hQJ9wHpicyKf7Ssk9dd7qcNzmUuFXAHf86oomAOU1dhVW80VeJT+dMZw+4SFWh+PXHpk+nIjQYJ7349aRFzt+3TpGC78uRxOA8grGGFasy2VAZBg/npRodTh+75reofxk+jDWHT7NNyfOWh2Oy+WeOs/WvEot/OqC7hnlFbbkVrK7+CxP3JRCz1Bt9egJD01Non/vUL9sIK+FX87RBKAs195uWJ6Vy5B+vfhhRkLXCyiXiAgL5rFZyXyZX82X+VVWh+MyVXW2wq87xmvhV1c0ASjLrT1YzuHyWp6am6qn6x52741DGNw3nN9n5fpNA/mLhV/6nf9d06NNWaq1rZ0X1uWRFhupH9ZZIDwkiCfnpJBz8hzrD5+2Opyr1tjSxp92HGe2Fn45RROAstTHe0sorKpn6bxUgrTVoyXuGB/PsOjerFiXS5uPN5C/WPi1RN/9O0UTgLJMY0sbL204xtiEKOamx1odTsAKDurBU/NSyTtdR2aO7/Zlutjx69pBfZg0XAu/nKEJQFnmvV0nKK9p5Jn52urRat8bNYj0QX14cf0xmlt9s4H8tmNV5J3Wwq/u0ASgLFHX1Mrrm/OZktyfycnRVocT8Hr0EJ5ekMaJMw18sOek1eFckZXZRcRo4Ve3aAJQllidXUR1fTNPzx9hdSjKbmZqDDckXsOrG49xodm3GsjnnbYXfk0aqneSdYPuKeVxZ+ub+ePWQualxzI2IcrqcJSdiPD0/BFUnG/inR3FVofTLZcKv24canUoPkUTgPK4N7YWUNfcqo3evdCEpH7MTIvhv78ooLaxxepwnFJV18Qn35SyaHw8/bTwq1s0ASiPOl3byFtfFnP72DhSYyOtDkd1Ytm8NM41tLBya6HVoTjlUuGXdvzqNk0AyqNe3XSMtnbDz+doo3dvNSquL7eMHsTK7CKq6pqsDuc7Xez4NXvEAJIHaOFXd2kCUB5zvLqe9786yT0ThjCkfy+rw1Hf4am5qTS2tPH6Zu9uIJ+5r4yqOi38ulKaAJTHvLThGMFBws9mJ1sdiurC8JgI7rw+nnd3Hqf03AWrw+mUMYaV2YWMGBiphV9XSBOA8ojcU+f5dF8pD05OYkCfcKvDUU540n6Z7pUN3tlAPjvfXvg1bZgWfl0hTQDKI1asyyUiNJhHZmirR18RF9WTH00cwkd7SyiorLM6nG9Zue1i4dcgq0PxWZoAlNt9c+Is6w+f5ifThxHVS2/T8yWPzUomLLgHL673rgbyeafP80VeJT+eOJSwYG0gdKU0ASi3W7Eul/69Q/X72X1QdEQYi6cm8dn+cg6W1lgdziWrs4sIC+7BjyZq4dfV0ASg3OrL/Cq+zK/msVnJ9A4LtjocdQWWTBtG354hXtNAvtpe+HXH9Vr4dbU0ASi3Mcbw+6xcBvcN594btTerr+rbM4SfzhzO5txKdhefsToc3t15Qgu/XEQTgHKbdYdPk3PyHD+fk0p4iF6n9WUPTEokJjKM5f+wtnVkY0sbf9pZzKy0GC38cgGnEoCILBCRXBHJF5FfdjJ/qIhsFJH9IrJFROI7zPu9iBwSkSMi8orY79cSkXtE5IB9mX+IiH4nsB9pazc8vy6XYTG9WTQ+zupw1FXqGRrEE7OT+ar4DF/kVVoWR2aOvfBrmt5N5gpdJgARCQJeA24G0oF7RCTdYdgK4B1jzGjgWeA5+7KTgSnAaGAUcAMwQ0SCgZeBWfZl9gOPu+QZKa+QmVNK3uk6ls5NIzhITzT9wV03DCGhX0+WZ+XSbkHrSGMMq7YVMWJgJJO18MslnDkyJwD5xphCY0wz8D5wm8OYdGCT/fHmDvMNEA6EAmFACHAaEPtPb/sZQR+g7Cqeh/Iiza3tvLA+j5GD+3DzqIFWh6NcJDS4B7+Yk8qhslo+P3jK49vPzq8i9/R5FmvHL5dxJgHEAR1bBJXYp3WUAyyyP74diBSR/saYHdgSQrn9J8sYc8QY0wL8FDiA7YU/HVjV2cZF5CciskdE9lRWWnfqqZz3wZ6TnDxzgWXz0+ihjd79ym1j40iNjeD59bm0tnm2deSq7CKiI8JYOFY7frmKq87Nl2G7tPMNMAMoBdpEJBm4FojHljRmi8g0EQnBlgDGAYOxXQL6VWcrNsa8aYzJMMZkxMTEuChc5S4Xmtt4deMxJiT2Y2aq/n/5m6AewtJ5aRRW1vPJXs81kD92+jxbcm0dv7Twy3WcSQClQEKH3+Pt0y4xxpQZYxYZY8YBv7ZPO4ftbGCnMabOGFMHfA5MAsbaxxQY2y0FHwKTr/bJKOu9vaOYivNNPL1AG737q3npsYxJiOKlDXk0tXqmdeTqL7Xwyx2cSQC7gRQRSRKRUOBuILPjABGJFpGL6/oVsNr++AT2D33t7/pnAEewJZB0Ebn4FnGufbryYbWNLfz3lgJmpcVwQ2I/q8NRbiIiPDM/jbKaRv6864Tbt1dd18THe7Xjlzt0mQCMMa3Y7tDJwvYi/aEx5pCIPCsiC+3DZgK5IpIHxAK/tU//CCjAdq0/B8gxxqwxxpQB/wVsFZH92M4I/rfrnpaywh+3FlJzoYWl87TVo7+bkhzN5OH9+cOmfOqbWt26rfd22Qq/Fk9NdOt2ApFYWdTRXRkZGWbPnj1Wh6E6UVXXxPTfb2bWiAG8du94q8NRHrD3xFkWvb6dZfNSeXx2ilu20djSxtTfbeK6uL78n4cmuGUbgUBEvjbGZDhO15dLUmwAAA8fSURBVBu0lUu8vrmAptZ2ls7VVo+BYvyQa5ibHsv/t7WQcw3NbtnGxcKvxVO18MsdNAGoq1Z67gLv7jzOnePjGRaj5fmBZNm8NOqaWnnjC9c3kDfGsDrbVvg1JVkLv9xBE4C6ahc7Rj0xxz2XAZT3ShsYyb+NjeOt7UVU1Da6dN1f5ldz9JQWfrmTJgB1VQoq6/hobwn3TRxKXFRPq8NRFvj5nBRa2wyvbsp36XpXZhdq4ZebaQJQV+WF9XmEBffg0VnDrQ5FWWRo/97cdUMCf/nqBCeqG1yyzvwKW+HXj7Xwy600AagrdrC0hr/vL2fJ1CSiI8KsDkdZ6ImbUgjqIby00TWtI1dlF9sKv7SPhFtpAlBXbMW6XPr2DGHJdL1DI9DF9gnnwcmJ/PWbUvJOn7+qdVXXNfHJ3hIWjY+nv76xcCtNAOqKfFV0hi25lfx05nD6hIdYHY7yAo/MGE5EaPBVt458b9cJmrTwyyM0AahuM8awPOsoAyLDeGBSotXhKC9xTe9Q/n36MLIO2TrBXYmm1jbe2XGcmWkxJA+IdHGEypEmANVtW/Iq2V18lp/dlELPUP2ATv3Tw1OT6N87lOVZV3YWkLmvjKq6JpZo4ZdHaAJQ3dLebliRlUtCv57clZHQ9QIqoESEBfPorGSy86vYnl/VrWWNMazSwi+P0gSguuXzg6c4VFbLU3NTCQ3WPx/1bT+6cQiD+obz+6zuNZC/WPj1sBZ+eYwewcpprW3tPL8+l9TYCBaO0UbvqnPhIUE8eVMK+06eY8ORCqeXW2Uv/LpNC788RhOActone0sprKxn2bw0grTVo/oOd14fT1J0b1Y42UA+v+I8m7Xwy+M0ASinNLa08dKGPMYkRDE3PdbqcJSXCw7qwVNzU8k9fZ7MnLIux6/KLiZUC788ThOAcsqfd52grKaRZ+Zrq0flnFuuG0T6oD68sD6Plu9oIH+mvplP9pZwx/g4LfzyME0Aqkv1Ta28tjmfKcn9mZIcbXU4ykf06CE8PT+NE2ca+HDPycuOe2/ncZpa23l4SpIHo1OgCUA5YXV2EdX1zSzTVo+qm2amxZAx9Bpe2XiMxpZvN5Bvam3j7R3HmZEaQ0qsFn55miYA9Z3ONTTz5tZC5qXHMm7INVaHo3yMiPDMghGcrm3inR3F35q/JqfcVvg1Td/9W0ETgPpOb3xRSF1zqzZ6V1dsQlI/ZqTG8PqWAmobWy5NN8awclshabGRTNVLi5bQBKAuq6K2kbe2F/FvY+NIG6in5+rKPT0/jXMNLazcVnRp2vYC7fhlNU0A6rJe3ZRPa5vhF3O00bu6OqPi+nLLdYNYta2Q6romAFZuKyQ6IlQ7fllIE4Dq1InqBv7y1QnunpDAkP69rA5H+YFfzE3lQksbr28pIL+ijs25ldw/MZHwEC38skqw1QEo7/TShjyCg4SfzdZG78o1kgdEcMf4eP608zjHqxsIDe7BfRO18MtKegagviX31Hn+uq+UByYnEtsn3OpwlB95ck4KGNhw5DSLxmnhl9X0DEABtq962Hy0gsycMjYdrSAiLJhHpmujd+Va8df04kcTh/DW9mIenqq3flpNE0AAa2lrJzu/ijX7ylh3+DR1Ta1ER4Ry9w0J3HvjUK7pHWp1iMoP/fLmEdwxPp5ULfyynCaAANPebviq+AyZOWV8fqCcsw0tRIYH873rBrJwTBwTh/UjOEivDCr3CQsOYlRcX6vDUGgCCAjGGPaX1LAmp4zP9pdzqraRniFBzEmPZeGYwUxPjdav4FUqADmVAERkAfAyEASsNMb8vw7zhwKrgRjgDHCfMabEPu/3wC3YPnBeDzxpjDEiEgr8AZgJtAO/NsZ87IonpWzyTp8nc18Za/aXcby6gZAgYUbqAP7zlmuZc+0AeoVq/lcqkHX5CiAiQcBrwFygBNgtIpnGmMMdhq0A3jHGvC0is4HngPtFZDIwBRhtH5cNzAC2AL8GKowxqSLSA+jnoucU0E5UN7Bmfxlrcso4euo8PQQmD4/msZnJzB85kL69QqwOUSnlJZx5CzgByDfGFAKIyPvAbUDHBJAOPGV/vBn41P7YAOFAKCBACHDaPu9hYASAMaYd6F4HaXXJ6dpGPttfzpqcMvadPAfA9UOv4b8WjuR71w0iJlJvtVNKfZszCSAO6Phl3iXAjQ5jcoBF2C4T3Q5Eikh/Y8wOEdkMlGNLAH8wxhwRkSj7cv9LRGYCBcDjxpjTKKecrW/m84OnWJNTxs6iaoyB9EF9+OXNI/j+6EHEX6PVu0qp7+aqi8DLgD+IyIPAVqAUaBORZOBaIN4+br2ITAOO2KdtN8Y8JSJPYbuMdL/jikXkJ8BPAIYMCeyqwbqmVtYfPsWanHK25lXS2m4YFt2bJ2ancOuYwSQPiLA6RKWUD3EmAZQCCR1+j7dPu8QYU4btDAARiQDuMMacE5F/B3YaY+rs8z4HJmH7LKAB+MS+iv8LLO5s48aYN4E3ATIyMrruLu1nGlva2JJbwZqccjYePU1jSzuD+4azeGoSt44ZzMjBffSbFJVSV8SZBLAbSBGRJGwv/HcD93YcICLRwBn7tfxfYbsjCOAE8O8i8hy2S0AzgJfsdwGtwXYH0CbgJv71M4WA1tLWzpf5VazJKWfdoVOcb2qlf+9QfpiRwMIxgxk/5Bp69NAXfaXU1ekyARhjWkXkcSAL222gq40xh0TkWWCPMSYT2wv5cyJisF0Cesy++EfAbOAAtg+E/2GMWWOf9x/An0TkJaASeMh1T8v3tLcb9hw/S2ZOKWsPnOJMfTOR4cEsGDWQhWMHM2lYfy3QUkq5lBjjO1dVMjIyzJ49e6wOw2WMMRwsrSUzp5TP9pdTXtNIeEgP5lwby61jBjMzLUYLtJRSV01EvjbGZDhO10ogC+RXXCzQKqeoqt5eoBXDL28ewZxrY+kdpv8tSin301caDzl5xlaglbnvnwVak4b355EZw5g/ciBRvfSL15RSnqUJwI0qahv5+4FyMnPK+OaErUBr/JAo/p9b0/ne6EEMiNTv2ldKWUcTgIuda2jmHwdPkZlTxs7CatoNXDuoD/+xwFagldBPC7SUUt5BE4AL1De1suHIaTL3lbH1WCUtbYak6N48PjuFhWMGkTxAv/dcKeV9NAFcoabWNrbkVpKZU8bGI7YCrUF9w3loShK3jh7MqDgt0FJKeTdNAN3Q2tbO9oJqMnPKyDp0ivONtgKtH1yfwK1jBpMxVAu0lFK+QxNAF9rbDV+fOEvmvjLWHiinur6ZyLBg5o20FWhNGa4FWkop36QJoBPGGA6V1ZKZU8ZnOWWU1TQSFvyvBVrhIVqgpZTybZoAOsivqLv0ol9YVU9wD2F6agzPLBjBnPRYIrRASynlRwL+Fa3kbANrcmzNVA6X1yICE5P68+/Th3HzKC3QUkr5r4BMAJXnm/j7fttXMXx9/CwAYxOi+M330/n+6EEM6KMFWkop/xcwCaCmoYV/HCpnTU452wuqaDcwYmAkT89PY+GYwVqgpZQKOAGRAP7zrwf4v3tO0tJmGNq/F4/NSmbhmMGkxGqBllIqcAVEAoi/picPTEpk4djBXBfXVwu0lFKKAEkAj85MtjoEpZTyOlrBpJRSAUoTgFJKBShNAEopFaA0ASilVIDSBKCUUgFKE4BSSgUoTQBKKRWgNAEopVSAEmOM1TE4TUQqgeNXuHg0UOXCcFxF4+oejat7NK7u8de4hhpjYhwn+lQCuBoisscYk2F1HI40ru7RuLpH4+qeQItLLwEppVSA0gSglFIBKpASwJtWB3AZGlf3aFzdo3F1T0DFFTCfASillPpXgXQGoJRSqgNNAEopFaD8LgGIyAIRyRWRfBH5ZSfzw0TkA/v8XSKS6CVxPSgilSKyz/6zxAMxrRaRChE5eJn5IiKv2GPeLyLj3R2Tk3HNFJGaDvvqNx6KK0FENovIYRE5JCJPdjLG4/vMybg8vs9EJFxEvhKRHHtc/9XJGI8fj07G5fHjscO2g0TkGxH5rJN5rt1fxhi/+QGCgAJgGBAK5ADpDmMeBd6wP74b+MBL4noQ+IOH99d0YDxw8DLzvwd8DggwEdjlJXHNBD6z4O9rEDDe/jgSyOvk/9Hj+8zJuDy+z+z7IML+OATYBUx0GGPF8ehMXB4/Hjts+yngz539f7l6f/nbGcAEIN8YU2iMaQbeB25zGHMb8Lb98UfATeL+JsHOxOVxxpitwJnvGHIb8I6x2QlEicggL4jLEsaYcmPMXvvj88ARIM5hmMf3mZNxeZx9H9TZfw2x/zjedeLx49HJuCwhIvHALcDKywxx6f7ytwQQB5zs8HsJ3z4QLo0xxrQCNUB/L4gL4A77ZYOPRCTBzTE5w9m4rTDJfgr/uYiM9PTG7afe47C9e+zI0n32HXGBBfvMfjljH1ABrDfGXHZ/efB4dCYusOZ4fAl4Bmi/zHyX7i9/SwC+bA2QaIwZDaznn1lefdtebN9tMgZ4FfjUkxsXkQjgY+DnxphaT277u3QRlyX7zBjTZowZC8QDE0RklCe22xUn4vL48Sgi3wcqjDFfu3tbF/lbAigFOmbqePu0TseISDDQF6i2Oi5jTLUxpsn+60rgejfH5Axn9qfHGWNqL57CG2PWAiEiEu2JbYtICLYX2feMMZ90MsSSfdZVXFbuM/s2zwGbgQUOs6w4HruMy6LjcQqwUESKsV0mni0i7zqMcen+8rcEsBtIEZEkEQnF9iFJpsOYTOAB++M7gU3G/omKlXE5XCdeiO06rtUygR/b72yZCNQYY8qtDkpEBl687ikiE7D9Hbv9RcO+zVXAEWPMC5cZ5vF95kxcVuwzEYkRkSj7457AXOCowzCPH4/OxGXF8WiM+ZUxJt4Yk4jtNWKTMeY+h2Eu3V/BV7qgNzLGtIrI40AWtjtvVhtjDonIs8AeY0wmtgPlTyKSj+2Dxru9JK4nRGQh0GqP60F3xyUif8F2d0i0iJQA/xPbB2IYY94A1mK7qyUfaAAecndMTsZ1J/BTEWkFLgB3eyCJg+0d2v3AAfv1Y4D/BIZ0iM2KfeZMXFbss0HA2yIShC3hfGiM+czq49HJuDx+PF6OO/eXfhWEUkoFKH+7BKSUUspJmgCUUipAaQJQSqkApQlAKaUClCYApZQKUJoAlFIqQGkCUEqpAPX/A7f+v/nskj7rAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEEpIbz4m99n"
      },
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9G5oqgO1hCo"
      },
      "source": [
        "prediction=model.predict(test_generator).flatten()\n",
        "# prediction = tf.nn.sigmoid(prediction)\n",
        "prediction.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBjrJJjS82L8"
      },
      "source": [
        "np.mean(tf.where(prediction < 0.5, 0, 1) == y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-V7cpGJ74kt"
      },
      "source": [
        "preds = np.squeeze(tf.where(prediction >= 0.5, 1, 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNvK8W0W8QgX"
      },
      "source": [
        "np.mean(preds == y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fkl0toO1pTB"
      },
      "source": [
        "f1_score(test_datagen, prediction, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx7gIXdw5cJ1"
      },
      "source": [
        "imgs, labels = next(iter(test_generator))\n",
        "labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeaOKyPW5dS3"
      },
      "source": [
        "y.shape, prediction.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekAi6gTV6Eu8"
      },
      "source": [
        "x, y = next(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8QdHEFD6M4A"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMXea4gI6f-f"
      },
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niLZaFjM7Pkj"
      },
      "source": [
        "preds = np.argmax(prediction, axis=1)\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyTbzJy-63Fv"
      },
      "source": [
        "#f1_score(prediction, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGv1vCkmVkkp"
      },
      "source": [
        "model.evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vS2POG47A-R"
      },
      "source": [
        "np.squeeze(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zlXlJ1k68V9"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhmKJWvz6-Sp"
      },
      "source": [
        "img = PImage.open('gdrive/My Drive/Colab Notebooks/Human_Detection/image_2021_06_01T16_11_06_870Z.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG-jUoVDY976"
      },
      "source": [
        "img = np.array(img)\n",
        "img = np.resize(img, (224, 224, 3))\n",
        "img = img.reshape(1, 224, 224, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBli2YUUW8Te"
      },
      "source": [
        "prediction=model.predict(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEtNXJwkYrgh"
      },
      "source": [
        "tf.where(prediction < 0.5, 0, 1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}